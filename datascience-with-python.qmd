---
title: "Data Science with Python"
description: Documenting Data Science Ideas and Techniques
author: 
  name: Gideon Eshun
  url: mailto:fiiisnpires@gmail.com
format: 
  html:
    theme: 
      light: cosmo
      dark: darkly
    toc: true
    html-math-method: katex
title-block-banner: "#003865"
---

## Introduction to Data Science and Problem Solving

### Problem-Solving Skills

Data science is not just about working with data; it starts with a problem and the thinking process behind it. Organizations hire data scientists because they believe they have problems that data can address. At its core, data science is about problem-solving. While the tools and techniques used in data science evolve over time, the fundamental problem-solving skills remain the same.

For example, newer techniques like XGBoost often outperform older algorithms such as Decision Trees, though both serve the same purpose of making predictions based on data. What truly matters is the ability to think critically and approach problems with a willingness to learn.

Each phase of data science can be viewed as a problem-solving task. Defining the problem is the first challenge, as solving the wrong problem is a waste of time and resources. Problem definition determines what data needs to be collected. Collecting the right data in the appropriate amount is another problem that requires problem-solving skills. Analyzing the data to generate insights involves identifying patterns, trends, and relationships. For instance, a data scientist might analyze customer behavior to determine which products are frequently purchased together and use this insight for targeted marketing campaigns.

Python, our choice of programming language, is just one of the tools used to implement hypotheses about data. It's important to remember that the programming language or tool is secondary to the analytical thinking and problem-solving skills that drive data science projects.

#### Critical Thinking

Problem-solving in data science involves breaking down complex problems into smaller, manageable parts. This helps in identifying key issues and developing focused strategies. Critical thinking plays a crucial role in this process by evaluating information and making judgments. After defining the problem, one must:

-   Brainstorm possible solutions.

-   Evaluate them.

-   Select the best one.

Critical thinking helps in understanding the assumptions and limitations of different solutions and models, guiding the selection of the most suitable one based on available evidence.

### The Analyst's Reductionist Approach

An analyst, even if not working directly with data, employs a reductionist view to find underlying elements. When the resource being analyzed is data, this person becomes a data analyst. However, analysts also need a synthetic or system approach to understand why certain data is produced, which involves considering the bigger picture and engaging with stakeholders and subject-matter experts.

Analytical thinking involves understanding the building blocks or fundamentals and then constructing complex expressions from them. In programming, for instance, data types and operators are the basic building blocks. Understanding these primitives allows one to build more advanced computations. Similarly, in data science, understanding the basics of business need, data manipulation and analysis is crucial for creating sophisticated models and solutions.

Science often uses models to represent real-world phenomena, employing a reductionist approach to simplify complex realities. In data science, this can be seen in machine learning, where models are functions that take data as input and provide predictions as output. This approach allows for understanding and inferring real-world behaviors through simplified representations.

Data analysis does not start with analysis but with synthesis. This involves understanding the context of the project and how it fits into the bigger picture. It's essential to grasp the business problem that needs to be solved and the value it brings to the organization. Knowing the project's context helps ensure that the analysis aligns with the business goals and addresses the right issues.

### Identifying the Problem to Solve

A data scientist must clearly understand the business goal that the analysis will address. For instance, the goal might be to increase revenue or save costs. Ultimately, businesses are focused on financial outcomes or that which gives competitive advantage, so even time-saving measures should be translated into monetary value. Defining the value the data science project will bring to the business can convince business leaders to buy into the project.

#### Asking the Right Questions

To effectively address the business goal, asking the right questions is crucial. If the goal is to increase revenue, some pertinent questions might include:

-   What are the factors influencing revenue?

-   Which products and services are most profitable?

-   How can we optimize our operations to boost profitability?

-   What customer behaviors drive the most sales?

By asking these questions, data scientists can focus their analysis on areas that will have the most significant impact on the business, ensuring that their efforts are aligned with the organization's objectives.

## Introduction to Python Programming

Consider this analytic scenario:

> Between the years `2016` and `2020`, $KN^4$ company recorded the following revenues (in CAD): `12000, 23000, 15000, 10000, 18000` respectively. How do you help $KN^4$ understand if it's `2021` revenue is in line with historical revenues?

### Python as calculator

Currently, we do not know the revenue for 2021. One approach would be to compare it with the revenue from 2020 to determine if it falls short or exceeds by a certain percentage. This approach assumes that the most recent value is a good indicator of future performance.

However, relying solely on the 2020 revenue does not take into account the overall trend from previous years. To make a more informed comparison, we need a single representative number that combines all historical revenues. This can be achieved by calculating the mean (average) of the revenues from 2016 to 2020.

To determine the mean (average) revenue for $KN^4$ from 2016 to 2020, we use the following calculation:

```{python}
#| eval: false

(12000 + 23000 + 15000 + 10000 + 18000) / 5
# Output: 15600.0
```

If you were able to type this out and see a result, congratulations! You just wrote an expression that Python can interpret. Let's break down this expression to understand how Python processes it:

-   **Numbers:** Python recognizes `12000`, `23000`, `15000`, `10000`, and `18000` as integers (whole numbers).

-   **Operators:** The plus sign `+` is an arithmetic operator for addition, and the forward slash `/` is for division.

-   **Parentheses:** The parentheses `()` group the expressions, instructing Python to first add the integers and then divide the sum by another integer.

Here is how Python interprets this expression:

1.  **Addition:** Python adds the numbers together inside the parentheses: $12000 + 23000 + 15000 + 10000 + 18000 = 78000$

2.  **Division:** Python then divides the sum by 5: $\frac{78000}{5} = 15600.0$

Notice the result is `15600.0`, a number with a decimal point. Python calls this type of number a `float`, short for floating-point number. Floats allow us to deal with numbers that have fractional components, such as `3.142`.

#### Importance of Parentheses

Using parentheses helps ensure the correct order of operations. For example, omitting the parentheses in our original expression would result in a different calculation:

$$12000+23000+15000+10000+18000/5=63600.0$$

This incorrect result occurs because Python performs the division first ($18000 / 5 = 3600.0$) and then adds the other numbers ($12000 + 23000 + 15000 + 10000 + 3600.0 = 63600.0$).

By correctly using parentheses, we ensure that the addition is performed before the division, yielding the correct mean revenue.

#### Understanding Data Types and Operations in Python

In Python, every object has a data type, which defines how you can interact with it:

-   **Integers (`int`):** Whole numbers without a fractional component, e.g., `12000`.

-   **Floating-point numbers (`float`):** Numbers with a fractional component, e.g., `15600.0`.

Python correctly performs the addition `+` and division `/` operations on our numbers because it recognizes the context in which these operators are used. It's important to note that:

-   **Arithmetic Operators:** `+` and `/` are not the only arithmetic operators in Python. Other operators include `-` (subtraction), `*` (multiplication), and `%` (modulus) etc.

-   **Order of Operations:** Python follows the mathematical order of operations (PEMDAS/BODMAS). Without parentheses, the division would be performed before the addition, leading to an incorrect result.

### Arithmetic Mean as a Linear Combination

The method we used to compute the mean in our previous example gives us the arithmetic mean. We summed up all the historical revenues and, since we have five years of data, we divided the total by 5. This can be mathematically expressed as:

$$\frac{1}{5}(12000 + 23000 + 15000 + 10000 + 18000) \\ = \frac{1}{5}(12000) + \frac{1}{5}(23000) + \frac{1}{5}(15000) + \frac{1}{5}(10000) + \frac{1}{5}(18000)$$

```{python}
#| eval: false

0.2*12000 + 0.2*23000 + 0.2*15000 + 0.2*10000 + 0.2*18000
# Output: 15600.0
```

Thus, our new number (`15600.0`) is formed by taking one-fifth of each of the historical revenues and summing them up. Each historical revenue contributed to the new number by being scaled down by $\frac{1}{5} = 0.2$. Formally, this process is known as creating a linear combination of the historical revenues.

### The Concept of Linear Combination

A linear combination involves only two operations: multiplication by a scalar and the addition of terms. This concept is fundamental to many models used in data analysis, such as linear regression. When we use equal weights (scale factors) for each revenue, we are calculating the arithmetic mean. However, if we use different weights, we calculate a weighted mean.

The scale factor used in the arithmetic mean is intentionally chosen to be the inverse (reciprocal) of the number of items you are summing, $\frac{1}{n}$​. Mathematically, the arithmetic mean can be represented as:

$$\frac{1}{n}\sum_{i=1}^{n}x_i = \frac{\sum_{i=1}^{n}x_i}{n} = \frac{x_1+x_2+\dots+x_{n-1}+x_n}{n}$$

In linear algebra terms, this is akin to finding the dot product of a weight vector and a revenue vector. Essentially, we are extracting features from the revenue vector, and in this case, the feature is a single number that represents the average revenue.

$$w\cdot v = \vec{w}^{\intercal}\vec{v} = \sum_{i = 1}^{n}w_iv_i = w_1v_1 + w_2v_2 + \dots + w_nv_n$$

```{python}
#| eval: false

weights = [0.2] * 5 
revenues = [12000, 23000, 15000, 10000, 18000]

sum([weight * rev for weight, rev in zip(weights, revenues)])
# Output: 15600.0
```

### Benefits of Linear Models

Linear models, like the arithmetic mean, are easy to project or extrapolate. Since they follow a linear relationship, they can be extended to unseen data simply by continuing the line (or hyper-plane). Additionally, linear models are:

-   **Easy to understand:** Their simplicity makes them accessible for explanation and interpretation.

-   **Simple to train and deploy:** Linear models often require less computational power and time compared to more complex models.

By understanding these fundamental concepts, you can effectively utilize Python and linear combinations to analyze and interpret data, providing valuable insights for your organization.

### Another Kind of Mean

In our previous example, we chose to linearly combine our historical revenues to compute the arithmetic mean. However, there are other ways to aggregate historical records to derive a new value. One such method is the geometric mean, which involves finding the product of all the revenues and then taking the nth root (where n is the number of revenues).

For our revenues, the geometric mean can be computed as follows:

```{python}
#| eval: false

(12000 * 23000 * 15000 * 10000 * 18000) ** (1/5)
# Output: 15543.045
```

This method provides us with a different value compared to the arithmetic mean, but it still gives us a useful number to compare against our 2021 revenue. The mathematical representation of the geometric mean is:

$$
\left(\prod_{i = 1}^{n}x_i\right)^{\frac{1}{n}} = \sqrt[n]{x_1\times\dots\times x_{n-1}\times x_n}
$$

Another type of mean is the harmonic mean, which is useful when dealing with rates or ratios. To calculate the harmonic mean of our revenues, we use the following formula:

$$\frac{n}{\sum_{i=1}^{n}\frac{1}{x_i}} = \frac{n}{\frac{1}{x_1}+\frac{1}{x_2}+\dots+\frac{1}{x_{n-1}}+\frac{1}{x_n}}$$

In Python, we can compute it as follows:

```{python}
#| eval: false

5 / ((1/12000) + (1/23000) + (1/15000) + (1/10000) + (1/18000))
# Output: 14163.415
```

### Comparing the Means

Let's compare the arithmetic, geometric, and harmonic means:

-   **Arithmetic Mean (Am)**: `15600.0`

-   **Geometric Mean (Gm)**: `15543.04`

-   **Harmonic Mean (Hm)**: `14163.415`

These three means provide different perspectives on the data. The arithmetic mean is influenced by extreme values, while the geometric mean mitigates the impact of outliers by using multiplication and roots. The harmonic mean is most appropriate for rates or ratios.

Interestingly, there's a relationship between the three means. In general, for positive numbers, the following inequality holds:

$$Hm \leq Gm \leq Am$$

Additionally, there is a relationship involving the geometric mean, harmonic mean, and arithmetic mean:

$$Gm = \sqrt{Hm \times Am}$$

​While there is a slight discrepancy due to rounding and floating-point precision, the relationship generally holds.

### Understanding Floating-Point Arithmetic

In Python, floating-point numbers are approximations, which can lead to unexpected results in calculations:

```{python}
#| eval: false

0.2 + 0.2 + 0.2 == 0.6  # Output: False
```

This occurs because the internal representation of floating-point numbers may introduce small errors. When performing arithmetic operations, these tiny discrepancies can accumulate, leading to results that are slightly off from the exact mathematical value.

### What We've Learned About Python

So far, we've covered basic Python syntax and arithmetic operators such as addition (`+`), division (`/`), multiplication (`*`), and exponentiation (`**`). We also encountered different data types: our revenues are integers (e.g., `12000`), while the result of our mean calculations is a float (e.g., `15600.0`), indicated by the presence of a decimal point.

You can verify data types using the `type()` function in Python:

```{python}
#| eval: false

type(12000)  # Output: <class 'int'>
type(15600.0)  # Output: <class 'float'>
```

If we want the arithmetic mean to be an integer, we can use integer division (`//`) operator:

```{python}
#| eval: false

(12000 + 23000 + 15000 + 10000 + 18000) // 5
# Output: 15600
```

Understanding syntax, operators, and data types forms the foundation of programming in Python. With this knowledge, we can build more complex code and apply analytical methods to solve various problems.

### What We've Learned About Data Science

**Summarization and Central Tendency**

In data science, it's often more effective to summarize a set of numbers with a single representative value. This approach simplifies communication and interpretation. One common method for summarizing data is by calculating the mean. However, choosing the right type of mean---arithmetic, geometric, harmonic, or another---depends on the context and the nature of the data.

**Choosing the Right Mean**

Selecting the appropriate mean requires critical thinking and depends on several factors:

1.  **The Nature of the Data Generation Process**:

    -   If the process is additive, such as daily temperatures, the arithmetic mean is suitable.

    -   If the process is multiplicative or involves compounding effects, such as interest rates or investment returns, the geometric mean is more appropriate.

2.  **Characteristics of the Data Points**:

    -   The presence of outliers can significantly influence the arithmetic mean, making it less representative of the central tendency. In such cases, alternative measures like the median or trimmed mean might be more appropriate.

3.  **Business Objectives and Context**:

    -   The specific goals of the analysis can dictate the choice of mean. For example, understanding average growth rates over time for financial planning would benefit from using the geometric mean.

**Understanding Data Reduction**

Reducing a set of numbers to a single value while retaining as much relevant information as possible is a fundamental aspect of data science. This reductionist approach simplifies analysis and communication but requires careful consideration to avoid significant loss of information. The chosen summarization method should provide meaningful insights and align with the underlying data characteristics and business needs.

**Geometric Mean and Interactions**

The geometric mean's ability to account for interactions between values makes it particularly valuable in scenarios where values influence each other over time. For example, in investments, the growth of a portfolio in one year may affect its growth in subsequent years. This interaction is why the geometric mean is preferred for such cases, as it captures the compounding effect.

**Harmonic Mean in Machine Learning**

1.  **F1 Score**:

    -   **Combining Precision and Recall**: The F1 score, which is the harmonic mean of precision and recall, is a widely used metric in classification tasks. It provides a single measure of a model's performance by balancing the trade-off between precision and recall. $F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$​

    -   **Why Harmonic Mean**: The harmonic mean is used because it penalizes extreme values more than the arithmetic mean, ensuring that a model with high precision but low recall (or vice versa) does not achieve a high $F1$ score. This makes it a robust metric for imbalanced classification problems.

**Summary**

In conclusion, understanding the context and characteristics of your data is crucial in selecting the appropriate method for summarization. Whether using the arithmetic, geometric, or harmonic mean, each has its place in data analysis. Critical thinking and a clear understanding of the data generation process, the nature of the data, and the business objectives will guide you in making the right choice. This approach ensures that your summarization retains the most relevant information and provides valuable insights.
